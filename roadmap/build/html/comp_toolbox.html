<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>8. The Computational Toolbox &#8212; JWST Astronomy Data Analysis Tools Roadmap v0.1</title>
    
    <link rel="stylesheet" href="_static/agogo.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="top" title="JWST Astronomy Data Analysis Tools Roadmap v0.1" href="index.html" />
    <link rel="next" title="9. Graphics and Visualization" href="graphics.html" />
    <link rel="prev" title="7. Architecture" href="architecture.html" /> 
  </head>
  <body role="document">
    <div class="header-wrapper" role="banner">
      <div class="header">
        <div class="headertitle"><a
          href="index.html">JWST Astronomy Data Analysis Tools Roadmap v0.1</a></div>
        <div class="rel" role="navigation" aria-label="related navigation">
          <a href="architecture.html" title="7. Architecture"
             accesskey="P">previous</a> |
          <a href="graphics.html" title="9. Graphics and Visualization"
             accesskey="N">next</a> |
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a>
        </div>
       </div>
    </div>


<div style="background-color: white; text-align: left; padding: 10px 10px 15px 15px">
<a href="index.html"><img src="_static/logo.png" border="0" alt="py4sci"/></a>
</div>


    <div class="content-wrapper">
      <div class="content">
        <div class="document">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="the-computational-toolbox">
<h1>8. The Computational Toolbox<a class="headerlink" href="#the-computational-toolbox" title="Permalink to this headline">¶</a></h1>
<p>This section describes the specific software tools that are to be built.
It should be viewed as a <em>concept document</em> not a <em>requirements document.</em>
The discussion of each tool is brief, and comments are added about existing
infrastructure that can be used to build each tool.</p>
<p>Many of the tools should work equally well with ground-based data
or data from space observatories, but there is a need to include tools
for standard kinds of ground-based data analysis. These are included,
although the list may be less complete than for the JWST tools.</p>
<p>The figure below provides birds-eye view of the tools described in this section.</p>
<div class="figure" id="id8" style="width: 100%">
<a class="reference internal image-reference" href="_images/computational_toolbox.png"><img alt="computational toolbox overview" src="_images/computational_toolbox.png" style="width: 100.0%; height: 615.0px;" /></a>
<p class="caption"><span class="caption-text">A high-level categorization of the tasks described in this section. Many of
the nodes in this map have sub-nodes and sub-sub-nodes that are not shown
but would generally comprise separate tools. At the level of detail shown
here there are ~50 categories of tools. In the end this will probably expand
into of order 10<sup>3</sup> individual tools.</span></p>
</div>
<div class="section" id="general-purpose-multi-dimensional-array-analysis-tools">
<h2>8.1. General-purpose multi-dimensional Array Analysis tools<a class="headerlink" href="#general-purpose-multi-dimensional-array-analysis-tools" title="Permalink to this headline">¶</a></h2>
<p>The descriptions of the tools here are deliberately brief. The main goal is
to highlight the basic functionality. In <em>many cases</em> basic functionality already
exists within the various python scientific libraries. In those cases, the development
effort for astronomers is generally focused on building interfaces to make
them convenient to use on astronomical data sets. This includes:</p>
<ul class="simple">
<li>Consistent approaches to masking or rejecting data</li>
<li>Consistent approaches to handling of undefined data and masks</li>
<li>Consistent approaches to dealing with error arrays and data quality arrays</li>
<li>Consistent approaches to dealing with metadata, including WCS information</li>
<li>Consistent approaches to history and logging</li>
</ul>
<div class="section" id="interactive-image-measurements">
<h3>8.1.1. Interactive Image Measurements<a class="headerlink" href="#interactive-image-measurements" title="Permalink to this headline">¶</a></h3>
<p>The new tools need to have the kinds of functionality currently supplied
by IRAF&#8217;s <code class="docutils literal"><span class="pre">imexamine</span></code> tool. This includes:</p>
<ul class="simple">
<li>centroids</li>
<li>contours</li>
<li>3d surface plots</li>
<li>2d cuts</li>
<li>localized histograms</li>
<li>aperture photometry</li>
<li>basic statistics</li>
</ul>
</div>
<div class="section" id="basic-statistics">
<h3>8.1.2. Basic Statistics<a class="headerlink" href="#basic-statistics" title="Permalink to this headline">¶</a></h3>
<p>The  includes basic statistics like mean, median, standard deviation, minimum and maximum,
with optional masking, setting of a floor and ceiling on input values and rejection of
outliers.</p>
</div>
<div class="section" id="filtering">
<h3>8.1.3. Filtering<a class="headerlink" href="#filtering" title="Permalink to this headline">¶</a></h3>
<p>There is already rich set of image filtering tasks in the scipy <a class="reference external" href="http://docs.scipy.org/doc/scipy/reference/ndimage.html">ndimage</a>
module, the scipy <a class="reference external" href="http://docs.scipy.org/doc/scipy/reference/signal.html">signal</a> and
in <a class="reference external" href="http://scikit-image.org">scikit-image</a>. However, these do not always deal gracefully
with image masks, undefined values, or error arrays. The astropy <a class="reference external" href="http://docs.astropy.org/en/v0.2.1/nddata/index.html">nddata</a>
module is aimed at addressing this issue. Filtering includes the following, all in N dimensions,
where N is at least 3 for JWST data:</p>
<ul class="simple">
<li>smoothing</li>
<li>convolution</li>
<li>gradient detection</li>
<li>wavelets</li>
</ul>
</div>
<div class="section" id="surface-fitting">
<h3>8.1.4. Surface Fitting<a class="headerlink" href="#surface-fitting" title="Permalink to this headline">¶</a></h3>
<p>A very common operation for astronomical images is to fit a relatively smooth
line, surface, or multi-dimensional manifold to a data set (with optional
masking and iterative data rejection). This is closely related to smoothing, except
that the surface is parametized somehow. The following parametrizations
are common enough that they should be provided:</p>
<ul class="simple">
<li>orthogonal polynomials (e.g. chebyshev)</li>
<li>splines</li>
</ul>
</div>
<div class="section" id="interpolation">
<h3>8.1.5. Interpolation<a class="headerlink" href="#interpolation" title="Permalink to this headline">¶</a></h3>
<p>There are many, many applications that involve interpolation in dealing
with astronomical images.  A typical application involves estimating the
sky background associated with sources in the image. A set of background
estimates from &#8220;clean&#8221; regions in the image are usually interpolated to
the positions of the sources. Another example is in applying geometrical
transformations to images. The fluxes on a rectangular pixel grid are used
to estimate the fluxes that would have been measured on a different
pixel grid.</p>
<div class="section" id="relatively-certain">
<h4>8.1.5.1. Relatively Certain<a class="headerlink" href="#relatively-certain" title="Permalink to this headline">¶</a></h4>
<p>The following kinds of interpolation should be included:</p>
<ul class="simple">
<li>multi-dimensional linear and polynomial interpolation</li>
<li>spline interpolation</li>
</ul>
</div>
<div class="section" id="under-consideration">
<h4>8.1.5.2. Under Consideration<a class="headerlink" href="#under-consideration" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><a class="reference external" href="http://en.wikipedia.org/wiki/Inverse_distance_weighting">Inverse distance-weighted</a> interpolation, and variants that use local neighbors</li>
<li><a class="reference external" href="http://en.wikipedia.org/wiki/Natural_neighbor">Natural neighbor</a> interpolation</li>
<li><a class="reference external" href="http://wiki.scipy.org/Cookbook/RadialBasisFunctions">Radial basis function</a>) interpolation</li>
<li>Gaussian processes regression, or <a class="reference external" href="http://en.wikipedia.org/wiki/Kriging">Kriging</a>, commonly used in geospatial modeling</li>
<li>Band-limited interpolation (e.g. sinc or Lanczos)</li>
<li><a class="reference external" href="http://en.wikipedia.org/wiki/Drizzle_(image_processing)">Drizzling</a></li>
</ul>
</div>
</div>
<div class="section" id="geometric-transformations-and-resampling">
<h3>8.1.6. Geometric transformations and resampling<a class="headerlink" href="#geometric-transformations-and-resampling" title="Permalink to this headline">¶</a></h3>
<p>The toolbox will include a wide variety of ways to transform images.
Many of these involve resampling, and interpolation. Most of the framework
for doing this already exists in python numerical libraries.
For geometric transformations, easy things should be easy to perform:</p>
<ul class="simple">
<li>Block averaging or block replicating</li>
<li>Linear transformations (shift, magnify, rotate, transpose)</li>
</ul>
<p>Harder things should be possible:</p>
<ul class="simple">
<li>Affine transformations (preserving straight lines and planes)</li>
<li>Arbitrary geometric distortions</li>
<li>Standard map projections (extensive support for various projections exists in matplotlib,
but it is currently hard to extract the projected data for other uses).</li>
</ul>
<p>It is would be useful to make making the different interpolation options easily accessible
to the geometric-transformation tools.</p>
</div>
</div>
<div class="section" id="imaging">
<h2>8.2. Imaging<a class="headerlink" href="#imaging" title="Permalink to this headline">¶</a></h2>
<p>In this section, we focus on tools that are mainly needed for undispersed
images of astronomical sources. Some of these tools apply to images
that are spectrally dispersed as well, but most of those tools are discussed
in the spectroscopy section.</p>
<div class="section" id="image-registration-wcs-tools">
<h3>8.2.1. Image Registration &amp; WCS Tools<a class="headerlink" href="#image-registration-wcs-tools" title="Permalink to this headline">¶</a></h3>
<p>Even if JWST images are perfectly rectified by the standard pipeline, it will be frequently
necessary to register other images to the JWST images. The geometric distortion properties
of these images are sometimes unknown and must be derived using the data themselves.
The various tasks involved (many of which are in the IRAF <code class="docutils literal"><span class="pre">immatch</span></code> package) include:</p>
<ul class="simple">
<li>image distortion fitting</li>
<li>image rectification</li>
<li>aligning images</li>
<li>combining images to a common grid</li>
<li>matching catalogs (triangle matching)</li>
<li>image cross-correlation</li>
</ul>
</div>
<div class="section" id="nir-image-reduction-stacking">
<h3>8.2.2. NIR Image Reduction &amp; Stacking<a class="headerlink" href="#nir-image-reduction-stacking" title="Permalink to this headline">¶</a></h3>
<p>This would replace the functionality of the IRAF <code class="docutils literal"><span class="pre">irred</span></code> package.</p>
</div>
<div class="section" id="ccd-image-reduction-stacking">
<h3>8.2.3. CCD Image Reduction &amp; Stacking<a class="headerlink" href="#ccd-image-reduction-stacking" title="Permalink to this headline">¶</a></h3>
<p>This would replace the functionality of the IRAF <code class="docutils literal"><span class="pre">ccdred</span></code> package.</p>
</div>
<div class="section" id="peak-finding">
<h3>8.2.4. Peak Finding<a class="headerlink" href="#peak-finding" title="Permalink to this headline">¶</a></h3>
<p>Peak finding is a typical operation on astronomical images. It is the first step of
any source detection and photometry package, but is often useful by itself.
Routines to do this in scipy and scikit-image would serve as a starting point.</p>
</div>
<div class="section" id="image-segmentation">
<h3>8.2.5. Image Segmentation<a class="headerlink" href="#image-segmentation" title="Permalink to this headline">¶</a></h3>
<p>Image segmentation is often the next step after finding peaks. Pixels are
assigned to sources via some algorithm. The routines for image segmentation
in scipy and scikit-image serve as a good starting point. They provide
a rich set of options for tasks such as labeling pixels associated with HII
regions or clusters within an individual galaxy.</p>
</div>
<div class="section" id="image-cutouts">
<h3>8.2.6. Image Cutouts<a class="headerlink" href="#image-cutouts" title="Permalink to this headline">¶</a></h3>
<p>Obtaining cutouts of selected sources from a database of larger images
is a common operation, but one that has not been standardized. Most organizations
serving out data now support the IVOA
Simple Image Access Specification (<a class="reference external" href="http://www.ivoa.net/documents/SIA/">SIAP</a>).
However this does not solve the problem of how to organize the data or
determine footprints. The IVOA has a
draft of a <a class="reference external" href="http://www.ivoa.net/documents/latest/Footprint.html">footprint specification</a>
open for comments. Many of the institutions serving large data sets support
SIAP and are headed toward common standards for footprints. However, tools
are needed to help individuals and small groups accomplish the same functions
on their smaller datasets for their own use.</p>
</div>
<div class="section" id="psf-matching">
<h3>8.2.7. PSF Matching<a class="headerlink" href="#psf-matching" title="Permalink to this headline">¶</a></h3>
<p>The need to match the point-spread function between different images is
very common, and a place where existing tools need improvement. Typically
one wants to determine the convolution-kernel that, when applied to a high-resolution
image, produces an image with the point-spread function of a lower-resolution
image. Examples include matching the PSFs of a JWST NIRCam image to that of
a MIRI image. Or matching a JWST image to a ground-based image. The PSF kernel
may be spatially varying across the image. Sometimes one has PSF models for
each instrument that can be used to construct the PSF kernel. Other times, one must
rely on sources in the image, which may or may not be point sources.</p>
<p>A popular algorithm in ground-based astronomy is the <a class="reference external" href="http://adsabs.harvard.edu/abs/1998ApJ...503..325A">Alard-Lupton</a>
method of decomposing the kernel into a set of Gaussian basis functions.
This is widely used in the supernova-search community. It works very well
for typical ground-based PSFs but the Gaussian basis-function may not be the best
choice for PSFs with a lot of structure or broad wings.
<a class="reference external" href="http://adsabs.harvard.edu/abs/2012MNRAS.425.1341B">Becker et al. (2012)</a> discuss other
methods and promote a method using regularized delta functions.
Regardless of the method, the toolbox needs to have efficient, flexible tools for selecting
the sources to use for PSF matching, iteratively and perhaps interactively rejecting bad
ones, evaluating the results, extracting
the kernels, and applying them for photometry or image subtraction.</p>
</div>
</div>
<div class="section" id="spectra-and-spectral-extraction">
<h2>8.3. Spectra and Spectral Extraction<a class="headerlink" href="#spectra-and-spectral-extraction" title="Permalink to this headline">¶</a></h2>
<div class="section" id="spectral-extraction">
<h3>8.3.1. Spectral extraction<a class="headerlink" href="#spectral-extraction" title="Permalink to this headline">¶</a></h3>
<p>At the simplest level, spectral extraction means turning a two-dimensional
dispersed image into a one-dimensional spectrum. This involves separable steps:</p>
<ul class="simple">
<li>Identifying the pixels to be used for source and background;</li>
<li>Co-adding the pixels in the cross-dispersion direction according to a specified
weighting (and masking) scheme and subtracting background.</li>
</ul>
<p>Generally speaking, the task of spectral extraction does not include:</p>
<ul class="simple">
<li>Converting pixels to wavelength</li>
<li>Converting counts to flux</li>
</ul>
<p>Nevertheless, there need to be user-oriented tools layered on top of
spectral extraction that apply the dispersion solution and flux calibration.</p>
<p>While the JWST pipeline will generally attempt to extract scientifically
useful 1D spectra of the objects in the field, it is very likely that astronomers
will want to control the extraction in different ways. Some of this can be done
by tweaking pipeline parameters, but there also need to be general-purpose tools
for doing this driven from parameter files or GUIs or regions on an image display.</p>
<p>This software can become quite complex, depending on the level of sophistication.</p>
<p>A simple approach involves selecting a spectrum on a rectified image (where all
spectra are straight lines and where there is a linear wavelength scale per
pixel), extracting a rectangular region from this image and summing along columns
or rows. This is very useful for quick-look analysis, but often insufficient for
the final scientific analysis.</p>
<p>The next level of sophistication selects a curved spectrum on a non-rectified
image, where the wavelength scale may not be linear. Either the software traces
the spectrum, or has a pre-defined map of the spectral traces so that it can
extract the spectrum. It then applies the dispersion solution and either constructs
a 1D array with a linear (or logarithmic) relation between wavelength and pixel
number, or it constructs a table where each row has a wavelength.</p>
<p>There is also a further level of sophistication, which uses a
rectified, co-added image from multiple exposures as a tool by which to identify
source and background regions. However, these regions are then transformed back
into the reference frame of the original individual (probably dithered) exposures and the
spectral extraction is carried out there. This minimizes number of resampling
steps carried out on the data and simplifies the propagation of uncertainties.</p>
<p>It is a goal to support all three methods of spectral extraction, with both
GUI-specified extraction regions and regions specified via input parameters.</p>
</div>
<div class="section" id="resampling-combining-spectra">
<h3>8.3.2. Resampling &amp; combining spectra<a class="headerlink" href="#resampling-combining-spectra" title="Permalink to this headline">¶</a></h3>
<p>Resampling a 1D spectrum can mean taking a spectrum on one wavelength scale and
putting it on another scale. Or it can mean taking a table of fluxes and
wavelengths and turning it into an array with a specified
wavelength scale. Or it can mean taking a model spectrum and interpolating
it to find its values at the wavelengths of an observed spectrum. Resampling
involves interpolation and is therefore an approximation.  There are
many different ways to interpolate, each with its own strengths and weaknesses.
Many interpolation methods are already supported by scipy and numpy,
so the primary goal is to provide interfaces to these interpolation methods so that they
can be easily applied to astronomy data sets with attention to metadata, error arrays and masks.</p>
<p>Resampling 2D spectra is more complicated and often requires a detailed
specification of the image distortions and wavelength calibrations of the
instruments used to obtain the data. At the lowest level it is
just 2D interpolation. The main challenge is to develop a simple, yet general
mechanism to specify the image geometries.</p>
<p>Combining spectra involves co-adding or finding some robust measure of the
mean of data from several different sources. The weights often depend
on the uncertainties and masks. The co-added spectra should have
associated uncertainties when it is possible to compute them.</p>
</div>
<div class="section" id="visualization-interactive-analysis-splot">
<h3>8.3.3. Visualization &amp; interactive analysis (splot)<a class="headerlink" href="#visualization-interactive-analysis-splot" title="Permalink to this headline">¶</a></h3>
<p>An important functionality for the Graphical User Interface(s) is to provide
interactive viewing and manipulation of one-dimensional spectra. The
type of functionality needed includes that available in the
<a class="reference external" href="http://iraf.net/irafhelp.php?val=splot&amp;help=Help+Page">splot</a> package,
<a class="reference external" href="http://www.stsci.edu/institute/software_hardware/specview">SPECVIEW</a>,
<a class="reference external" href="http://www.sciops.esa.int/index.php?project=ESAVO&amp;page=vospec">VOSPEC</a>,
the STARLINK <a class="reference external" href="http://star-www.dur.ac.uk/~pdraper/splat/splat.html">SPLAT package</a>
or a variety of individually-maintained <a class="reference external" href="http://idlastro.gsfc.nasa.gov/other_url.html">IDL tools</a>.</p>
<p>Perhaps more important than the specific functionality is to develop a
framework to make it easy for astronomers, who are generally not experienced
GUI developers, to add functionality to the GUI for a particular science
application.</p>
</div>
<div class="section" id="emission-absorption-line-fitting">
<h3>8.3.4. Emission &amp; absorption line fitting<a class="headerlink" href="#emission-absorption-line-fitting" title="Permalink to this headline">¶</a></h3>
<p>The software tools need to include a variety of fitting functions and
fitting methods. Fitting functions should include simple Gaussians and
Lorentz and Voit profiles, as well as more elaborate functional forms.
The software should allow for convolution with a wavelength-dependent
line-spread function. It should provide a variety of minimization routines
and ways of treating uncertainties and missing data. It should work
well in regimes where the assumption of Gaussian uncertainties on the fluxes
is not valid (e.g. for very low counts/pixel). It should have ways to convert
the results into physical units. It should be straightfoward to use the
same software to assess uncertainties via resampling or Monte-Carlo
techniques.</p>
</div>
<div class="section" id="general-spectral-fitting">
<h3>8.3.5. General spectral fitting<a class="headerlink" href="#general-spectral-fitting" title="Permalink to this headline">¶</a></h3>
<p>In addition to fitting emission and absorption lines, there need to be tools
for estimating or fitting continua (used in line-fitting). This includes
allowing the user to interactively select regions to use for continuum fitting,
as well as providing algorithms for iteratively masking emission and
absorption features as part of the determination of the continuum spectrum.</p>
<p>There also need to be tools for fitting
heuristic or physical models to spectra, e.g.
along the lines of the contributed package <a class="reference external" href="http://www.pha.jhu.edu/~gak/specfit.html">specfit</a>
in STSDAS.</p>
</div>
<div class="section" id="line-lists">
<h3>8.3.6. Line lists<a class="headerlink" href="#line-lists" title="Permalink to this headline">¶</a></h3>
<div class="section" id="id1">
<h4>8.3.6.1. Relatively Certain<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h4>
<p>The toolbox should contain convenient, well-documented lists of the wavelengths of
lines commonly seen in astronomical objects.</p>
</div>
<div class="section" id="id2">
<h4>8.3.6.2. Under Consideration<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h4>
<p>It is less certain how far to push into the astrophysics of spectral analysis.
It might make sense to provide common line ratios (e.g. from
Case-B recombination), and to provide simple interfaces
to more sophisticated tools like <a class="reference external" href="http://www.nublado.org">CLOUDY</a>.</p>
</div>
</div>
<div class="section" id="slitless-spectroscopy">
<h3>8.3.7. Slitless spectroscopy<a class="headerlink" href="#slitless-spectroscopy" title="Permalink to this headline">¶</a></h3>
<p>HST and JWST each have two slitless spectrographs. The JWST NIRSpec
MOS can also mimic a slitless spectrograph. The lack of a slit creates
several challenges for slitless spectroscopy:</p>
<ul class="simple">
<li>Spectra from several sources can overlap;</li>
<li>Overlap can include a zeroth-order image or spectra from higher orders;</li>
<li>Spectra taken at different rotations can be used to overcome some of the effects of blending;</li>
<li>The wavelength calibration depends critically on knowing the source positions; and</li>
<li>The convolution kernel for a spectral feature can be quite broad because it not truncated by a slit.</li>
</ul>
<p>For HST, slitless spectroscopy has been supported by the <a class="reference external" href="http://axe-info.stsci.edu">AxE package</a>.
The 3D-HST Treasury Program developed a separate set of tools.
Regardless of the ability of the JWST pipeline to meet all the calibration needs,
tools for observers to inspect the original 2D spectra and extracted 1D spectra,
manipulate and re-run the extraction, model the line-spread function, and deal with the
source confusion are essential.</p>
<p>Searches for emission lines (such as Lyman-alpha lines from very distant galaxies)
are hopeless without dealing with most of these issues. It would clearly be
of interest to observers to have a tool that searches for emission lines in the
data automatically, accounting for the difficulties of spectral overlaps and the
fact that the S/N for a significant detection is dependent on the size of the
line-emitting region and the underlying background due to sky and galaxy continuum.</p>
</div>
<div class="section" id="instrumental-corrections">
<h3>8.3.8. Instrumental corrections<a class="headerlink" href="#instrumental-corrections" title="Permalink to this headline">¶</a></h3>
<p>For JWST and HST, the instrumental corrections are the job of the pipeline. The
pipeline parameters and tasks themselves can be modified and re-run by the user.
These include:</p>
<ul class="simple">
<li>converting counts to calibrated fluxes in physical units;
applying sensitivity, flat-field and illumination corrections</li>
<li>converting pixel positions to wavelengths</li>
</ul>
<p>To the extent that the assumptions for different instruments can be standardized,
it would be useful to include the building blocks for applying instrumental
corrections for other instruments in the general set of tools. However, because
this depends on standardized formats for calibration information, it will require
broad community involvement. One way forward would be to develop a prototype of
applying insrumental corrections to a popular ground-based spectrograph, using
the same calibration philosophy that is used for JWST, and document this as a template
for other instruments.</p>
<p>More importantly, there are tasks involved in deriving these corrections that
are in common to HST and JWST instrument scientists and the large community of astronomers
needing to calibrate other instruments:</p>
<ul class="simple">
<li>deriving the instrumental sensitivity from standard-star observations;</li>
<li>deriving the instrumental flat field;</li>
<li>deriving instrumental illumination corrections;</li>
<li>deriving the instrumental dispersion solution; and,</li>
<li>deriving the absolute wavelength calibration</li>
</ul>
<p>In the case of ground-based observations, some of these calibrations need to be applied
night by night, while for the space instruments there is no need to worry about
atmospheric variations and other time dependencies (e.g. thermal changes of the
instrument) tend to be much slower.</p>
</div>
<div class="section" id="environmental-corrections">
<h3>8.3.9. Environmental corrections<a class="headerlink" href="#environmental-corrections" title="Permalink to this headline">¶</a></h3>
<p>It is useful to separate environmental corrections from instrumental
corrections, with the distinction that the environmental corrections generally
happen outside of the telescope. These include:</p>
<ul class="simple">
<li>Correcting spectra to heliocentric, galacto-centric or cosmic-flow
corrected velocities;</li>
<li>Shifting spectra to the rest frame;</li>
<li>Correcting for interstellar reddening and extinction;</li>
<li>Correcting for scattered light;</li>
<li>Modeling and/or removing telluric features; and,</li>
<li>Correcting for airmass and atmospheric extinction</li>
</ul>
<p>The last couple items on this list are unique to ground-based instruments.
The rest are important for JWST and HST, although some of these are done in the
pipeline.</p>
</div>
</div>
<div class="section" id="d-spectroscopy">
<h2>8.4. 3D Spectroscopy<a class="headerlink" href="#d-spectroscopy" title="Permalink to this headline">¶</a></h2>
<p>In 3D spectroscopy, instead of having a two-dimensional image, the scientist
is presented with a three-dimensional image, with two dimensions of spatial
information and one dimension of wavelength information. There are some
unique challenges to these kinds of data. However, there is also a lot of commonality
with 1D and 2D spectroscopy (for example in extracting 1D spectra or
fitting spectral features).</p>
<p>For JWST 3D spectra (in NIRSpec and MIRI), an image slicer reorganizes
the incoming light to provide non-overlapping spectra of <em>slitlets</em> &#8211;
small rectangular slices of the sky. These dispersed spectra are collected
in a 2D detector and can then be re-assembled into a 3D data cube in the
pipeline, after correcting for various distortions in the optical system.
Generically, the data-analysis tools allow astronomers to view, select,
and analyze data in this 3D space.</p>
<p>It is worth pointing out that this is not the only way of storing the
3D information. It is the most convenient way for a user to view the
3D data, but it involves resampling. Provided one has the tools to map
from the original detector reference frame to the rectified 3D image
frame, one can imagine developing tools that allow viewing and selection
in a rectified 3D image, but do the extraction and analysis on the
original pixels. Such tools are more challenging to develop, but are
part of the trade space being considered.</p>
<p>In this section, for the sake of brevity,
we concentrate mostly on tasks that are specific to the 3D nature of the data.
Once one has selected regions to used for the source spectrum and the background,
many of the tasks (e.g. fitting spatial or spectral models) are functionally
equivalent to the 1D or 2D cases.</p>
<div class="section" id="d-image-arithmetic-filtering-thresholding-and-masking">
<h3>8.4.1. 3D image arithmetic, filtering, thresholding, and masking<a class="headerlink" href="#d-image-arithmetic-filtering-thresholding-and-masking" title="Permalink to this headline">¶</a></h3>
<p>Basic tools for arithmetic operations on 3D data cubes will be provided.
This includes simple operations like
add/subtract/multiply/divide as well as applying more complex functions.
All of this generic functionality already exists in numpy and scipy, so
the development effort will be in developing interfaces that do sensible
things with metadata, errors and masks.</p>
<p>The basic tasks for thresholding, masking, peak-finding, convolution,
filtering, and general signal processing also mostly exist in the
numpy/scipy infrastructure and will not require a huge effort to incorporate
into 3D spectroscopy tools.</p>
<p>The standard mechanisms for
<a class="reference external" href="http://docs.scipy.org/doc/numpy/reference/arrays.indexing.html#basic-slicing">slicing</a>
arrays, doing statitistics, and projecting/summing
along dimensions will be available.</p>
</div>
<div class="section" id="align-combine-datacubes">
<h3>8.4.2. Align &amp; combine datacubes<a class="headerlink" href="#align-combine-datacubes" title="Permalink to this headline">¶</a></h3>
<p>An alarmingly common operation will be to try to align and combine data
cubes. This could be to produce spectra of the same sources over a wider
spectral range (i.e. combining in the wavelength direction) or to produce co-added
spectra of sources taken in separate (possibly dithered) exposures. The JWST
pipeline will deal automatically with some of the latter, when the images fall
in a pre-defined association. However, users will no doubt want to create their
own associations.</p>
<p>If the image alignment is not already known, the tools
described in the Imaging section above can be used to align
extracted 2D projections of the 3D data cube. If this is shift,
rotation and scaling, the alignment can be fairly simple. If it involves
geometric distortion, it can be quite complex.</p>
<p>The image combination operation can be challenging. In the wavelength direction, the spectra
may overlap and may have different wavelength scales. The user may want to
weight the spectra via some algorithm and may want to apply masking. The
user will generally want to produce an error array to accomany the combined
data dube. These operations almost certainly involve interpolation, and therefore
involve some science-specific decisions. The same considerations apply
to the spatial dimension, which could in principle include image distortions.
The challenge is to create a set of tools that include:</p>
<ul class="simple">
<li>a simple interface for quicklook or for cases where the exact details
of the image combination are unimporant;</li>
<li>more elaborate interfaces and documentation to allow users to tailor
the image alignment and combination to their science goals.</li>
</ul>
</div>
<div class="section" id="fit-remove-continuum">
<h3>8.4.3. Fit &amp; remove continuum<a class="headerlink" href="#fit-remove-continuum" title="Permalink to this headline">¶</a></h3>
<p>Fitting and removing a continuum is a generic task that applies to 1D, 2D and 3D
spectroscopy.  In a 1D spectrum, the astronomer usually specifies regions to use
for fitting the continuum &#8211; either interactively or via some algorithm that
iteratively detects emission and absorption features and masks them out.
The fitting algorithm could be parametric, or could involve interpolation.
The choice depends on the data and the science application. Tools need to
be flexible enough support many options.</p>
<p>The philosophy of region-selection
selection in the wavelength dimension is the same for 2D or 3D data, but
now the spectra have to be combined somehow either to provide a visual
display of a 1D co-added spectrum of a given spatial region to allow the
astronomer to select the regions to use (or mask out) in the fitting, or
there needs to be a specification of how the iterative masking algorithm
averages over the spatial pixels. Sometimes there will be spatial as
well as spectral masks (e.g. to remove foreground sources).</p>
<p>In a 1D spectrum there is one continuum spectrum.
In the 2D and 3D cases there are more choices to be made.  In 2D spectral analysis,
there could be a single 1D continuum spectrum that is modulated by the spatial
profile of the source, or there could be separate continuum spectra for each
pixel in the spatial dimension. The approach depends on the S/N and the science
application. Similarly for a 3D data cube, the science and S/N may dictate
whether one tries to derive and divide out a single continuum spectrum
for all spatial pixels, a continuum spectrum that varies smoothly in some
fashion along spatial coordinates (e.g. via fitting or interpolation) or
a separate continuum spectrum for each spatial pixel.</p>
</div>
<div class="section" id="extract-1d-spectra-from-regions">
<h3>8.4.4. Extract 1D spectra from regions<a class="headerlink" href="#extract-1d-spectra-from-regions" title="Permalink to this headline">¶</a></h3>
<p>A common operation on 3D data cubes is to extract 1D spectra from
specified regions. These regions could be selected:</p>
<ul class="simple">
<li>interactively on the 3D visualization tool</li>
<li>via adaptive spatial binning such as <a class="reference external" href="http://adsabs.harvard.edu/abs/2003MNRAS.342..345C">Voronoi tesselation</a></li>
<li>via thresholds in S/N or isophotes, applied to specific wavelength ranges</li>
<li>via scripts</li>
<li>via tables.</li>
</ul>
<p>These regions can have a variety of shapes, which
may or may not be connected. The tools should allow the selection of
background regions as well.</p>
<p>The tools should support different ways of combining spectra
(e.g. sums, means with and without weighting, or medians). The tools should
return error arrays and bad-pixel masks when relevant.</p>
</div>
<div class="section" id="construct-a-2d-image-from-3d-cube">
<h3>8.4.5. Construct a 2D image from 3D cube<a class="headerlink" href="#construct-a-2d-image-from-3d-cube" title="Permalink to this headline">¶</a></h3>
<p>A typical operation on a 3D data cube will be to construct a
2D image of some specific region in wavelength (e.g. emission lines)
This operation may include some interpolation over masked pixels in the wavelength
dimension, so is not quite as simple as summing along one
dimension of a 3D array.</p>
<p>One use of such a projected image is to drive automated algorithms
for 1D spectral extraction from the data cube. For example: find
peaks in the image, create extraction apertures around those peaks
and extract the associated 1D spectra. The same tasks used for
peak-finding and image segmentation described earlier in the Imaging
section can be used for this.</p>
</div>
<div class="section" id="point-source-extraction">
<h3>8.4.6. Point-source extraction<a class="headerlink" href="#point-source-extraction" title="Permalink to this headline">¶</a></h3>
<p>The 1D extraction of the spectra of point sources is a special case.</p>
<div class="section" id="id3">
<h4>8.4.6.1. Relatively Certain<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h4>
<p>The tools should support optimal extraction weighted by the PSF profile,
or simple aperture extraction.</p>
</div>
<div class="section" id="id4">
<h4>8.4.6.2. Under Consideration<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h4>
<p>More challenging, but possible, is to
derive the 1D individual spectra of point-sources in very crowded fields
where the PSF wings substantially overlap. This involves simultaneously
fitting for the fluxes of the overlapping sources, and results in 1D
spectra that have significant covariance with the spectra of their
neighbors.</p>
</div>
</div>
<div class="section" id="line-profile-fitting-correlation">
<h3>8.4.7. Line-profile fitting &amp; correlation<a class="headerlink" href="#line-profile-fitting-correlation" title="Permalink to this headline">¶</a></h3>
<p>3D spectroscopy is often used to analyze kinematics. At the root level,
this involves extracting and analyzing 1D spectra of spatial regions within the
image, but the desired data product returned to the user is generally not
a big table of numbers, but rather some more informative visualization.
Use cases include:</p>
<ul class="simple">
<li>Fit a Gaussian to and derive centroids and higher order moments
of an emission line profile to derive gas kinematics of emission.
The input is a 3-D datacube sub-region. The output is a set of
2-D images that describe the Gaussian fits, and velocity centroid,
dispersion and higher order moments of the profile.</li>
<li>Fit <em>two</em> Gaussian profiles to an emission line profile to derive
gas kinematics of emission. The input is a 3-D datacube
sub-region. The output is two sets of 2-D images that describe
the velocity centroid, dispersion and higher order moments of the
profile.</li>
<li>Fit a user input 1-D spectrum (e.g., instrumental line profile
model) to an emission line profile to derive gas kinematics of the
emission. The input is a 3-D datacube sub-region and 1-D spectral template.
The output is two sets of 2-D images that describe the velocity
centroid, dispersion and higher order moments of the profile.</li>
<li>Correlate the IFU datacube to a template spectrum to generate
stellar kinematic diagnostics from absorption line spectra in a
continuum source. Inputs are the 3-D datacube region
plus a template 1-D spectrum, outputs are 2-D image maps
of the velocity and dispersion.</li>
</ul>
<p>It will clearly be beneficial to have user-friendly GUI-driven tools
for this kind of work, layered on top of the simpler tools that do the
spectral extraction and fitting.</p>
</div>
<div class="section" id="interactive-3d-data-cube-vizualization">
<h3>8.4.8. Interactive 3D data-cube Vizualization<a class="headerlink" href="#interactive-3d-data-cube-vizualization" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="d-plotting-of-3d-data">
<h3>8.4.9. 2D Plotting of 3D data<a class="headerlink" href="#d-plotting-of-3d-data" title="Permalink to this headline">¶</a></h3>
<p>The 3D-spectroscopy toolbox needs to contain a variety of types of
two-dimensional plots. There is a clear need for interactive plots
to work with the data-analysis tools themselves. There is also a clear
need for publication-quality graphics.</p>
<p>Use cases include:</p>
<ul class="simple">
<li>Create figures using two 2-D images -– e.g. using
a continuum emission image, overplot contours from the other image.
User inputs include display levels for image and contour levels and
a color table. (This is already largely doable in the current version
of DS9, although it could be made more convenient).</li>
<li>Create a velocity channel map using a 3-D input cube</li>
<li>Create a 3-D plot view with parameters from the 3D visualzation tool inputs</li>
<li>Create a figure presenting multiple 2-D images (not linked in velocity) using input from the 3D visualization tool.</li>
<li>Create a plot with multiple 1-D spectra from the 3D visualization tool.</li>
<li>Create recipes or canned wrapper macros that permit creation of some of these figures with
fewer clicks by the user, and no external saves.</li>
</ul>
<p>Most of these plot types are easily supported in matplotlib (in both
quicklook and publication-quality forms), so the
software development can be concentrated primarily on providing the linkage to
the 3D visualization tool, and on layers to make use of data models
and metadata to put coordinate systems and physical units on the plots.</p>
</div>
<div class="section" id="derive-phyiscal-parameters-from-related-spectra">
<h3>8.4.10. Derive phyiscal parameters from related spectra<a class="headerlink" href="#derive-phyiscal-parameters-from-related-spectra" title="Permalink to this headline">¶</a></h3>
<div class="section" id="id5">
<h4>8.4.10.1. Under Consideration<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h4>
<p>Deriving physical parameters from spectra was beyond the scope of most
IRAF tasks, but is clearly of use to astronomers. The key question is whether
tools can be made generic enough that they support a broad community of users.
Specific use cases include:</p>
<ul class="simple">
<li>Provide the means to take a few inputs –- such as emission line images or
emission line datacubes -– to derive physical parameters (i.e.,
<img class="math" src="_images/math/493e3b4c79402433c6895e3e0e60a80fe45846a3.png" alt="n_e"/> from [Fe II]
line ratio maps or <img class="math" src="_images/math/800f40855dd0314a978dbddfc0d0bda36d0576b1.png" alt="A_v"/> from H2 line maps).</li>
<li>Have several canned relations available automatically (such as gas parameters
for [Fe II] and H2 line regions, or common physical parameters derived from
optical emission lines in red-shifted galaxies).</li>
</ul>
</div>
</div>
<div class="section" id="velocity-field-fitting">
<h3>8.4.11. Velocity-field fitting<a class="headerlink" href="#velocity-field-fitting" title="Permalink to this headline">¶</a></h3>
<div class="section" id="id6">
<h4>8.4.11.1. Under Consideration<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h4>
<p>A fairly common operation in galaxy research is to fit a velocity field
with a model (e.g. tilted disks, with or without constraints on the
one-dimensional rotation curve). Ideally, the fitting is done on the
ful data cube, but the visualization is on lower-dimensional slices.
Tools for such modeling exist, particularly in the radio community.
Further investigation is prudent before developing a new tool.</p>
</div>
</div>
<div class="section" id="catalog-overlap">
<h3>8.4.12. Catalog overlap<a class="headerlink" href="#catalog-overlap" title="Permalink to this headline">¶</a></h3>
<p>Tools should be provided to ingest catalogs and use them to overlay on
3D data cubes or drive spectral extraction.</p>
</div>
</div>
<div class="section" id="source-extraction-morphology-and-photometry">
<h2>8.5. Source extraction, morphology and photometry<a class="headerlink" href="#source-extraction-morphology-and-photometry" title="Permalink to this headline">¶</a></h2>
<p>Various types of source extraction have already been mentioned above in the
imaging and spectroscopy sections.  The toolbox needs to include well-documented
tools for the following:</p>
<ul class="simple">
<li>Aperture photometry</li>
<li>PSF construction</li>
<li>PSF-kernel construction for matching images with different resolution</li>
<li>Multi-band crowded-field photometry with or without positional and flux priors
(incorporating priors is an area of weakness of existing codes).</li>
<li>Point-source detection in crowded field</li>
<li>Faint-galaxy source detectection</li>
<li>Faint-galaxy photometry</li>
<li>Faint-galaxy morphology</li>
</ul>
<p>This is an area where very capable tools already exist both inside and outside of IRAF.
This includes:</p>
<ul class="simple">
<li><a class="reference external" href="http://www.astromatic.net/software/sextractor">SExtractor</a>, a stand-alone
monolithic C program for faint-galaxy detection and photometry driven by a traditional parameter-file interface.</li>
<li><a class="reference external" href="http://users.obs.carnegiescience.edu/peng/work/galfit/galfit.html">GALFIT</a>
for fitting parametric models to galaxy images.</li>
<li><a class="reference external" href="http://astro-staff.uibk.ac.at/~m.barden/GALAPAGOS/">GALAPAGOS</a> A set of IDL
scripts that tie together SExtractor and GALFIT.</li>
<li><a class="reference external" href="http://adsabs.harvard.edu/abs/1987PASP...99..191S">DAOPHOT</a>  for crowded-field stellar photometry.</li>
<li><a class="reference external" href="http://americano.dolphinsim.com/dolphot/">DOLPHOT</a> for crowded-field stellar photometry.</li>
<li><a class="reference external" href="https://github.com/AbhijitSaha/DoPhot">DOPHOT</a> for crowded-field stellar photometry.</li>
<li><a class="reference external" href="http://www.noao.edu/noao/staff/mighell/matphot/">MATPHOT</a> for crowded-field stellar photometry.</li>
</ul>
<p>The stellar-photometry codes all take somewhat different approaches to deriving and parametrizing
the PSF and fitting the PSF to the crowded images. A version of DAOPHOT exists
within IRAF.</p>
<p>Because these are very capable (and complex) codes, there is currently
not much urgency in the HST+JWST community to create new codes. That said,
many of these codes are maintained by a single person, with no guarantee
they will be maintained indefinitely, and there are some limitations of current
codes.</p>
<p>In summary, these capabilities are needed whether by ensuring maintenance and interoperability
with a existing codes, or developing new tools.</p>
<p>Regardless of whether exiting monolithic packages for doing star and galaxy photometry
are supported as part of the toolset for JWST observers, it would be very
valuable to provide modular tools for astronomers to experiment with new
algorithms. The tools for image filtering, segmentation, and morphology within
scipy and scikit-image are already quite powerful, although it is unclear that
they would be fast enough for a production environment.</p>
</div>
<div class="section" id="simulation">
<h2>8.6. Simulation<a class="headerlink" href="#simulation" title="Permalink to this headline">¶</a></h2>
<p>Simulations are absolutely essential for analyzing modern astronomical data.
Simulations are the best way to estimate the the flux biases, uncertainties,
selection functions, and completeness of samples of stars or galaxies measured
in an image or a survey. Typically one would like to either construct purely
simulated images with realistic simulations of the S/N, PSF, and instrumental
charactiistics, or one would like to insert simulated objects into the real
images. To prevent the uncertainties in the analysis from dominating the
final uncertainties, one will typically insert many more sources into the
images than true sources, but do this a few sources at a time to keep the
crowding more or less the same.</p>
<p>In IRAF, simulations have been supported by the <a class="reference external" href="http://iraf.net/irafhelp.php?val=artdata&amp;help=Help+Page">ARTDATA</a>,
which is flexible and quite fast. This package does not include tools for
modeling model instrument characteristics.</p>
<p>A flexible simulation package should include the following:</p>
<ul class="simple">
<li>Source shapes (point sources, various galaxy models)</li>
<li>A library of astronomical source spectra</li>
<li>The ability to apply an instrumental response function to spectra (e.g.
<a class="reference external" href="http://stsdas.stsci.edu/pysynphot/">pysynphot</a>)</li>
<li>Distribution functions to describe populations of sources with varying fluxes or spectral properties (e.g. luminosity functions)</li>
<li>Spatial distribution functions</li>
<li>At a minimum, the ability to convolve with point-spread functions</li>
<li>Poisson and Gaussian noise models</li>
</ul>
<p>Certain aspects of this are already supported by pysynphot, which takes
input spectra and instrument throughputs and calculates count rates.</p>
<p>A more sophisticated simulation suite would attempt to model the full effects of the
environment, optics, and detector. The <a class="reference external" href="http://www.lsst.org/lsst/science/simulations">LSST Image Simulator</a>,
treats each incident photon individually, accounting for the effects of the atmosphere
and optics, non-uniformities in the detectors, charge diffusion, etc.
Various proprietary simulators exist for the JWST
instruments, but there are currently no plans to support these for general
observers. Nevertheless, it is important to have reasonably high-fidelity
simulations that include the specific characteristics of the instruments in order
to develop the JWST pipeline. It takes more effort to develop these for general
use, but they would undoubtedly be useful to many observers.</p>
<p>It would also be extremely useful for the simulation suite to provide access various kinds of sky models:</p>
<ul class="simple">
<li>A Milky Way model for star counts</li>
<li>A Milky Way model for extinction</li>
<li>A diffuse sky-background model (including zodiacal light, galactic diffuse emission, and extragalactic background radiation)</li>
<li>Hertsprung-Russell diagrams and a tool to build stellar populations</li>
<li>A tool for building synthetic galaxy spectra for an assumed star-formation history and chemical evolution</li>
<li>Cosmological galaxy-evolution simulations</li>
</ul>
<p>The situation for these is very similar to that for photometry packages.
There are many existing codes that work well and are widely used in the community.
There is thus little pressure to create new codes and at least the initial focus
should be providing access and interoperability.</p>
</div>
<div class="section" id="other-tools">
<h2>8.7. Other tools<a class="headerlink" href="#other-tools" title="Permalink to this headline">¶</a></h2>
<p>This section lists other astronomy-specific tools not mentioned above that will
be commonly used. Many of these tools exist in some form in astropy already.</p>
<div class="section" id="utilities-for-reading-writing-and-manipulating-fits-files-and-headers">
<h3>8.7.1. Utilities for reading, writing, and manipulating FITS files and headers<a class="headerlink" href="#utilities-for-reading-writing-and-manipulating-fits-files-and-headers" title="Permalink to this headline">¶</a></h3>
<p>The standard for python has been <a class="reference external" href="http://www.stsci.edu/institute/software_hardware/pyfits">pyfits</a>
for the past few years. This is now incorporated into astropy as astropy.io.fits. In addition
to reading, writing, and creating files, it offers standard pythonic ways of accessing the
metadata in the image headers.</p>
<p>The equivalent of the following IRAF tasks are needed:</p>
<ul class="simple">
<li><a class="reference external" href="http://iraf.net/irafhelp.php?val=hselect&amp;help=Help+Page">hselect</a> - select files on disk via header keywords using various boolean operations</li>
<li><a class="reference external" href="http://iraf.net/irafhelp.php?val=hedit&amp;help=Help+Page">hedit</a> - batch editing of keywords</li>
<li>eheader - an STSDAS task for editing keywords in emacs or vi</li>
</ul>
<p>When fits IO is needed in C it will be provided by <a class="reference external" href="http://heasarc.gsfc.nasa.gov/fitsio/">CFITSIO</a>.</p>
</div>
<div class="section" id="utilities-for-reading-writing-and-manipulating-tables">
<h3>8.7.2. Utilities for reading, writing and manipulating tables<a class="headerlink" href="#utilities-for-reading-writing-and-manipulating-tables" title="Permalink to this headline">¶</a></h3>
<p>Astronomers deal with tabular data constantly. The storage formats includ
ASCII files with various formats, FITS, VO Tables, and databases.
For small tables, the routines for manipulating the table and doing
operations (plotting statistics, model fitting, etc.) can be independent
of the table format once the table is read in. For large data sets
that do not fit in memory, this is not as straightfoward.</p>
<p>Various utilities exist within python and astropy for dealing
with tabular data, all of which have slightly different purposes:</p>
<ul class="simple">
<li><a class="reference external" href="http://stsdas.stsci.edu/pysynphot/">astropy.table</a>,</li>
<li><a class="reference external" href="http://www.pytables.org/moin">pytables</a>,</li>
<li><a class="reference external" href="http://pandas.pydata.org">pandas</a>.</li>
</ul>
<p>There is work to be done to improve the convience to astronomers for:</p>
<blockquote>
<div><ul class="simple">
<li>reading and writting various formats</li>
<li>dealing with missing data</li>
<li>dealing with uncertainties</li>
<li>interpolation (with a rich set of options)</li>
<li>gridding irregularly sampled data</li>
</ul>
</div></blockquote>
<p>This is a place where well-designed tools with good documentation and
tutorials can save the community a lot of time.</p>
</div>
<div class="section" id="utilities-for-dealing-with-astronomical-times-and-positions">
<h3>8.7.3. Utilities for dealing with astronomical times and positions<a class="headerlink" href="#utilities-for-dealing-with-astronomical-times-and-positions" title="Permalink to this headline">¶</a></h3>
<p>Astropy now includes tools for manipulating
world coordinate systems in <a class="reference external" href="http://docs.astropy.org/en/latest/wcs/index.html">astropy.wcs</a>.
It includes basic functionality for manipulating times and dates in
<a class="reference external" href="http://docs.astropy.org/en/latest/time/index.html">astropy.time</a>. The
open-source <a class="reference external" href="http://rhodesmill.org/pyephem/">pyephem</a> packages is well
supported and offers utilities for time and position as well as for computing
epheremerides of the solar-system bodies and satellites.</p>
<div class="section" id="id7">
<h4>8.7.3.1. Under Consideration<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h4>
<p>Perry include something about SOFA?</p>
<p>If the license on the <a class="reference external" href="http://www.iausofa.org/tandc.html">SOFA</a> astronomy library
can be made compatible with the astropy license, then it will be incorporated with
a python wrapper.</p>
</div>
</div>
<div class="section" id="utilities-for-model-fitting-and-optimization">
<h3>8.7.4. Utilities for model fitting and optimization<a class="headerlink" href="#utilities-for-model-fitting-and-optimization" title="Permalink to this headline">¶</a></h3>
<p>This section needs work....</p>
<p>Model fitting is an essential part of the toolbox. It is required in
many steps of instrument calibration, as well as in the analysis and interpretation
of science data. It requires both full-featured GUI interfaces that allow
data selection and interactive manipulation of fitting parameters, as well
as fast and robust routines that can be used repeatedly in fitting large
data sets.</p>
<p>The tool set should certainly include various kinds of standard functions
such as Gaussians and polynomials. Within IRAF there are ~80 different tasks
that involve fitting, from general curve and surface fitting like
<a class="reference external" href="http://iraf.net/irafhelp.php?val=utilities.curfit&amp;help=Help+Page">curfit</a>,
<a class="reference external" href="http://iraf.net/irafhelp.php?val=utilities.polyfit&amp;help=Help+Page">polyfit</a> and
<a class="reference external" href="http://iraf.net/irafhelp.php?val=imsurfit&amp;help=Help+Page">imsurfit</a>,
to more specialized routines for fitting continuum in spectra, fitting sky background,
fitting standard-star photometry, or fitting ellipses.</p>
<p>The scipy <a class="reference external" href="http://docs.scipy.org/doc/scipy/reference/optimize.html">optimize package</a>
includes a variety of optimization options.  Eric Tollerud, one of the founders
of astropy, has provided a somewhat higher level framework for model fitting,
including a customized GUI in <a class="reference external" href="http://pythonhosted.org/PyModelFit/">PyModelFit</a>.</p>
<p>There are a couple of python versions of
Craig Markwardt&#8217;s popular <a class="reference external" href="http://www.physics.wisc.edu/~craigm/idl/">IDL fitting library</a>.</p>
</div>
</div>
</div>


          </div>
        </div>
      </div>
        </div>
        <div class="sidebar">
          <h3>Table Of Contents</h3>
          <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="exec_summary.html">1. Executive Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="intro.html">2. The vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="intro.html#guiding-principles">3. Guiding principles</a></li>
<li class="toctree-l1"><a class="reference internal" href="intro.html#why-do-we-need-new-tools">4. Why do we need new tools?</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_cases.html">5. Science Use Cases</a></li>
<li class="toctree-l1"><a class="reference internal" href="infrastructure.html">6. Technologies and Infrastructure</a></li>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">7. Architecture</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">8. The Computational Toolbox</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#general-purpose-multi-dimensional-array-analysis-tools">8.1. General-purpose multi-dimensional Array Analysis tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="#imaging">8.2. Imaging</a></li>
<li class="toctree-l2"><a class="reference internal" href="#spectra-and-spectral-extraction">8.3. Spectra and Spectral Extraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#d-spectroscopy">8.4. 3D Spectroscopy</a></li>
<li class="toctree-l2"><a class="reference internal" href="#source-extraction-morphology-and-photometry">8.5. Source extraction, morphology and photometry</a></li>
<li class="toctree-l2"><a class="reference internal" href="#simulation">8.6. Simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#other-tools">8.7. Other tools</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="graphics.html">9. Graphics and Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="timeline.html">10. Development Timeline</a></li>
</ul>

          <div role="search">
            <h3 style="margin-top: 1.5em;">Search</h3>
            <form class="search" action="search.html" method="get">
                <input type="text" name="q" />
                <input type="submit" value="Go" />
                <input type="hidden" name="check_keywords" value="yes" />
                <input type="hidden" name="area" value="default" />
            </form>
          </div>
        </div>
        <div class="clearer"></div>
      </div>
    </div>

    <div class="footer-wrapper">
      <div class="footer">
        <div class="left">
          <div role="navigation" aria-label="related navigaton">
            <a href="architecture.html" title="7. Architecture"
              >previous</a> |
            <a href="graphics.html" title="9. Graphics and Visualization"
              >next</a> |
            <a href="genindex.html" title="General Index"
              >index</a>
          </div>
          <div role="note" aria-label="source link">
              <br/>
              <a href="_sources/comp_toolbox.txt"
                rel="nofollow">Show Source</a>
          </div>
        </div>

        <div class="right">
          
    <div class="footer" role="contentinfo">
        &#169; Copyright 2013, Henry Ferguson, Perry Greenfield, and Alberto Conti.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.4.8.
    </div>
        </div>
        <div class="clearer"></div>
      </div>
    </div>

  </body>
</html>